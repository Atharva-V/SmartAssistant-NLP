{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the beautifulsoup \n",
    "# and request libraries of python.\n",
    "import requests\n",
    "import bs4\n",
    "import time\n",
    "import re\n",
    "import wikipedia\n",
    "\n",
    "def get_when(text):\n",
    "\n",
    "    user_agent_desktop = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\\\n",
    "    'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 '\\\n",
    "    'Safari/537.36'\n",
    "\n",
    "    headers = { 'User-Agent': user_agent_desktop}\n",
    "    # Make two strings with default google search URL\n",
    "    # 'https://google.com/search?q=' and\n",
    "    # our customized search keyword.\n",
    "    # Concatenate them\n",
    "    url = 'https://google.com/search?q=' + text\n",
    "  \n",
    "    # Fetch the URL data using requests.get(url),\n",
    "    # store it in a variable, request_result.\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    start = time.process_time()\n",
    "    # Creating soup from the fetched request\n",
    "    code = resp.status_code  # HTTP response code\n",
    "    if code == 200:\n",
    "        soup = bs4.BeautifulSoup(resp.text,\"lxml\")\n",
    "\n",
    "    #debug html\n",
    "    #with open('url2.txt', 'w', encoding='utf-8') as f_out:\n",
    "    #f_out.write(str(soup))\n",
    "\n",
    "    try:\n",
    "        x=re.search(r'aria-level=\"3\"(.*?)<\\/div>', str(soup))\n",
    "        start=(x.span())[0]\n",
    "        end=(x.span())[1]\n",
    "        r=(str(soup))[start:end]\n",
    "        r1=re.search(r'(div class=\".*>)(.*)(?=<)',r)\n",
    "        res=r1.group(2)\n",
    "        return res\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        x=re.search(r'aria-level=\"3\"(.*?)<\\/div>', str(soup))\n",
    "        start=(x.span())[0]\n",
    "        end=(x.span())[1]\n",
    "        r=(str(soup))[start:end]\n",
    "        r1=re.search(r'(?<=>)(.*)(?=<)',r)\n",
    "        res=r1.group()\n",
    "        res1=res.split(\" \")\n",
    "        if res1[-1]==\"...\":\n",
    "            pass\n",
    "        else:\n",
    "            return res\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        x=re.search(r'aria-level=\"3\".*?<div class.*?</s', str(soup))\n",
    "        start=(x.span())[0]\n",
    "        end=(x.span())[1]\n",
    "        r=(str(soup))[start:end]\n",
    "        date=re.search(r'(?<=>)[0-9]* [a-zA-Z]*(?=<)',r)\n",
    "        day=re.search(r'(?<=>)[a-zA-Z]+(?=<)',r)\n",
    "        year=re.search(r'20[0-9][0-9]',r)\n",
    "        res=[day.group(),date.group(),year.group()]\n",
    "        return res\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
